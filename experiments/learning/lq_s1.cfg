[DEFAULT]
path                = results_lq_s1
repetitions         = 30
iterations          = 30
seed                = 42
action_filter       = None
defensive           = True
biased_offpolicy    = True
estimator           = gpomdp
baseline            = zero
sigma_noise         = 0
stepper             = "ConstantStepper(1e-4)"
horizon             = 10
mu_init             = 0
logstd_init         = -1.0
learn_std           = False
batchsize           = 200

[onpolicy]
experiment          = grid
ce_batchsizes       = None
stepper             = ["ConstantStepper(1e-4)", "Adam(1e-1)", "Adam(1e-2)", "Adam(1e-4)"]
horizon             = [10, 50]
sigma_noise         = [0, 2]
mu_init             = [0, 0.5, 1]
logstd_init         = [0.0, -1.0, -2.0, -3.0]


[offpolicy]
experiment          = grid
ce_batchsizes       = 100
batchsize           = 100
stepper             = ["ConstantStepper(1e-4)", "Adam(1e-1)", "Adam(1e-2)", "Adam(1e-4)"]
horizon             = [10, 50]
sigma_noise         = [0, 2]
mu_init             = [0, 0.5, 1]
logstd_init         = [0.0, -1.0, -2.0, -3.0]


# [learn_policy_std]
# experiment          = list
# learn_std           = True
# batchsize           = [100, 50]
# ce_batchsizes       = [None, 50]
