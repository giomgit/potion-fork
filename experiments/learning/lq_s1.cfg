[DEFAULT]
path                = results_lq_s1
repetitions         = 30
iterations          = 30
seed                = 42
action_filter       = None
defensive           = True
biased_offpolicy    = True
estimator           = gpomdp
baseline            = zero
sigma_noise         = 0
stepper             = "ConstantStepper(1e-4)"
horizon             = 10
mu_init             = 0.9
logstd_init         = -1.0
learn_std           = False
batchsize           = 300

[onpolicy]
experiment          = grid
ce_batchsizes       = None
logstd_init         = [-1.0, -2.0, -3.0]


[offpolicy]
experiment          = grid
ce_batchsizes       = 150
batchsize           = 150
logstd_init         = [-1.0, -2.0, -3.0]
