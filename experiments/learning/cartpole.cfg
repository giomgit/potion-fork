[DEFAULT]
path                = results_cartpole
repetitions         = 10
iterations          = 200

# Policy
mu_init             = 0.0
logstd_init         = 0.0
learn_std           = False

# Environment
environment         = 'cartpole'
sigma_noise         = 0
horizon             = 200

# Common algorithm parameters
baseline            = 'peters'
estimator           = 'gpomdp'
seed                = 42
stepper             = 'ConstantStepper(1e-2)'

# Offpolicy algorithm parameters
biased_offpolicy    = True
ce_batchsizes       = None
ce_use_offline_data = True

[onpolicy]
experiment          = list
batchsize           = [20,50,100]

[offpolicy]
experiment          = list
batchsize           = [20, 15, 10, 50, 30, 25, 100, 50, 50]
defensive_batch     = [ 0,   0,  5,  0,  0,  10,  0, 20, 0]
